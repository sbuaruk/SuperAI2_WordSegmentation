{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Segmentation_Preprocessing_Optimizer1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing original .txt "
      ],
      "metadata": {
        "id": "bcw9gW592Q4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6Dgvd3ry7r",
        "outputId": "cdf20b10-b7e4-49df-e24e-f75604eb36ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1BL-o_bXbbbnd3GPCW2DpJ-pW2X341e6F \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import original .txt dataset for LST20-21 corpus\n",
        "!gdown --id '1BL-o_bXbbbnd3GPCW2DpJ-pW2X341e6F'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/LST20-21.zip\" -d \"/content/LST20-21\""
      ],
      "metadata": {
        "id": "Rtepn9R0r_Ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9255bb04-a4f1-43d7-8f0b-8c85ba980205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/LST20-21.zip\n",
            "  inflating: /content/LST20-21/LST20-21.zipfile  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/LST20-21/LST20-21.zipfile\" -d \"/content/LST20-21\""
      ],
      "metadata": {
        "id": "TbWLbtN1uJy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dac431-749f-4987-cfe0-961190333f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/LST20-21/LST20-21.zipfile\n",
            "   creating: /content/LST20-21/LST20-21/\n",
            "   creating: /content/LST20-21/LST20-21/Annotation Guidelines/\n",
            "  inflating: /content/LST20-21/LST20-21/Annotation Guidelines/LST20 Annotation Guideline.pdf  \n",
            "  inflating: /content/LST20-21/LST20-21/Annotation Guidelines/LST20 Brief Specification.pdf  \n",
            "  inflating: /content/LST20-21/LST20-21/LST20.zip  \n",
            "  inflating: /content/LST20-21/LST20-21/LST21.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/LST20-21/LST20-21/LST20.zip\" -d \"/content/LST20\""
      ],
      "metadata": {
        "id": "8Q0pBtlKuRYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "FxzssTTBu0Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir('/content/LST20/LST20/test/')\n",
        "\n",
        "# files = glob('/content/LST20/LST20/train/*')\n",
        "# files = glob('../*.txt')\n",
        "print('Number of files: ', len(files))\n",
        "print(files[3])"
      ],
      "metadata": {
        "id": "ZjdH7RUruZdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac874957-10c3-4949-b609-960d2c2de96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files:  967\n",
            "._T12774.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating .txt file"
      ],
      "metadata": {
        "id": "h110yy2Vb_dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "ra10HbciisIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lst20_to_bestIcorpus(PATH_MAIN, filename):\n",
        "  # PATH_MAIN = '/content/LST20/LST20/train/'\n",
        "  txt = ''\n",
        "  with open(os.path.join(PATH_MAIN, filename), 'r') as current_file:\n",
        "      for line in current_file:\n",
        "          data = line.strip().split('\\t')\n",
        "          tem_txt = data[0].replace('_', ' ')\n",
        "          txt += str(tem_txt) + '|'\n",
        "  return txt"
      ],
      "metadata": {
        "id": "dN3sZWyg4NH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH = '/content/LST20/LST20/train/'\n",
        "# data_txt = lst20_to_bestIcorpus(PATH, files[0])\n",
        "# # print(data_txt)\n",
        "# with open('test.txt', 'w') as f:\n",
        "#     f.write(data_txt)"
      ],
      "metadata": {
        "id": "AcGzGiJ76SF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# txt_dir_path = \"\"\n",
        "\n",
        "# txt_path = []\n",
        "# for root, dirs, files in os.walk(txt_dir_path):\n",
        "#     for name in files:\n",
        "#         if name.endswith('.txt'):\n",
        "#             txt_path.append(os.path.join(root, name))"
      ],
      "metadata": {
        "id": "UomIILPuu78G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir('/content/LST20/LST20/eval/')\n",
        "PATH = '/content/LST20/LST20/eval/'\n",
        "\n",
        "os.mkdir('/content/LST20_eval_prep')\n",
        "\n",
        "for f in files:\n",
        "  try:\n",
        "    data_txt = lst20_to_bestIcorpus(PATH, f)\n",
        "\n",
        "    with open('/content/LST20_eval_prep/{}_prep.txt'.format(f.replace('.txt','')), 'w') as f:\n",
        "      f.write(data_txt)\n",
        "  except UnicodeDecodeError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "rrcpX9caazDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r \"/content/LST20_prep.zip\" \"/content/LST20_train_prep\" \"/content/LST20_eval_prep\" \"/content/LST20_test_prep\""
      ],
      "metadata": {
        "id": "Cl4w9NuSgK0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB"
      ],
      "metadata": {
        "id": "4Yr3HCSjqK-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/IMDB Dataset.csv.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "WRw423jf5t6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "kKGsPJXveQyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "mN-D0X3n6C8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJuHN0eb6Ob_",
        "outputId": "1160ed04-c4a8-4673-c5c4-93adb85ae5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = shuffle(df, n_samples=250, random_state=0)"
      ],
      "metadata": {
        "id": "DcZhDfDVuvdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test['review']\n",
        "print(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3zydfhG6RSz",
        "outputId": "a3a6a8a6-5050-4642-91ae-3578537e3d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11841    John Cassavetes is on the run from the law. He...\n",
            "19602    It's not just that the movie is lame. It's mor...\n",
            "45519    Well, if it weren't for Ethel Waters and a 7-y...\n",
            "25747    I find Alan Jacobs review very accurate concer...\n",
            "42642    This movie is simply awesome. It is so hilario...\n",
            "                               ...                        \n",
            "43777    The monster from Enemy Mine somehow made his w...\n",
            "19933    It's particularly hard for a director to captu...\n",
            "33740    What was this supposed to be? A remake of Fish...\n",
            "33711    (possible spoilers)<br /><br />Someone once as...\n",
            "10393    ATTENTION, SPOILER!<br /><br />Many people tol...\n",
            "Name: review, Length: 250, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying WordPunctTokenizer for word segmentation"
      ],
      "metadata": {
        "id": "pCohjO4Q2q0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()"
      ],
      "metadata": {
        "id": "BYHGy3ibdC5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/IMDB_train')\n",
        "\n",
        "for i, d in enumerate(df_test):\n",
        "  d = re.sub(r'<[^<>]*>', '', d)\n",
        "  d = tokenizer.tokenize(d)\n",
        "\n",
        "  txt = ''\n",
        "  for t in d:\n",
        "    txt += t + '|'\n",
        "\n",
        "  with open('/content/IMDB_train/imdb_{}.txt'.format(i), 'w') as f:\n",
        "    f.write(txt)"
      ],
      "metadata": {
        "id": "cVDOMDrscay_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/IMDB_train.zip\" \"/content/IMDB_train\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDYCSdW1eecf",
        "outputId": "1a67f7aa-2dcc-43a4-9856-d5da664fa7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/IMDB_train/ (stored 0%)\n",
            "  adding: content/IMDB_train/imdb_127.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_226.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_26.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_163.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_43.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_214.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_194.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_109.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_160.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_22.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_132.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_84.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_218.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_14.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_187.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_134.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_37.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_153.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_5.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_135.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_11.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_235.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_185.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_6.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_10.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_169.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_189.txt (deflated 55%)\n",
            "  adding: content/IMDB_train/imdb_224.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_29.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_118.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_33.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_2.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_120.txt (deflated 24%)\n",
            "  adding: content/IMDB_train/imdb_35.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_20.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_225.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_172.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_100.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_161.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_176.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_81.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_141.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_42.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_186.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_7.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_206.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_199.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_91.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_106.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_213.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_103.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_108.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_46.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_177.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_207.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_107.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_55.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_8.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_246.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_49.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_105.txt (deflated 35%)\n",
            "  adding: content/IMDB_train/imdb_90.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_82.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_143.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_148.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_30.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_144.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_16.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_64.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_83.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_69.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_131.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_41.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_126.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_182.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_124.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_88.txt (deflated 37%)\n",
            "  adding: content/IMDB_train/imdb_158.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_242.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_62.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_220.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_114.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_89.txt (deflated 36%)\n",
            "  adding: content/IMDB_train/imdb_98.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_142.txt (deflated 33%)\n",
            "  adding: content/IMDB_train/imdb_32.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_60.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_180.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_146.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_1.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_222.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_212.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_166.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_123.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_198.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_249.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_248.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_183.txt (deflated 32%)\n",
            "  adding: content/IMDB_train/imdb_219.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_12.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_234.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_80.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_168.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_59.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_208.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_76.txt (deflated 58%)\n",
            "  adding: content/IMDB_train/imdb_233.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_86.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_195.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_236.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_200.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_101.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_178.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_27.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_52.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_232.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_152.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_63.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_203.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_28.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_204.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_240.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_75.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_231.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_193.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_165.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_159.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_184.txt (deflated 32%)\n",
            "  adding: content/IMDB_train/imdb_70.txt (deflated 32%)\n",
            "  adding: content/IMDB_train/imdb_39.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_216.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_48.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_97.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_72.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_173.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_191.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_9.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_215.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_119.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_94.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_129.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_230.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_227.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_205.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_112.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_115.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_113.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_45.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_61.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_47.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_15.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_190.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_24.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_85.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_128.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_125.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_211.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_217.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_157.txt (deflated 25%)\n",
            "  adding: content/IMDB_train/imdb_147.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_74.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_244.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_145.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_241.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_221.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_56.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_136.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_3.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_239.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_238.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_57.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_4.txt (deflated 39%)\n",
            "  adding: content/IMDB_train/imdb_247.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_50.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_197.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_170.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_140.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_228.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_38.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_68.txt (deflated 24%)\n",
            "  adding: content/IMDB_train/imdb_155.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_58.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_87.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_53.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_54.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_110.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_93.txt (deflated 23%)\n",
            "  adding: content/IMDB_train/imdb_139.txt (deflated 37%)\n",
            "  adding: content/IMDB_train/imdb_171.txt (deflated 28%)\n",
            "  adding: content/IMDB_train/imdb_23.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_111.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_130.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_17.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_181.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_66.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_151.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_40.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_117.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_192.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_95.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_149.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_21.txt (deflated 37%)\n",
            "  adding: content/IMDB_train/imdb_196.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_121.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_96.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_19.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_245.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_36.txt (deflated 40%)\n",
            "  adding: content/IMDB_train/imdb_13.txt (deflated 41%)\n",
            "  adding: content/IMDB_train/imdb_18.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_164.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_78.txt (deflated 51%)\n",
            "  adding: content/IMDB_train/imdb_34.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_67.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_51.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_175.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_31.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_243.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_138.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_25.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_150.txt (deflated 52%)\n",
            "  adding: content/IMDB_train/imdb_154.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_102.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_201.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_71.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_229.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_188.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_79.txt (deflated 53%)\n",
            "  adding: content/IMDB_train/imdb_167.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_137.txt (deflated 30%)\n",
            "  adding: content/IMDB_train/imdb_65.txt (deflated 49%)\n",
            "  adding: content/IMDB_train/imdb_156.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_174.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_202.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_44.txt (deflated 50%)\n",
            "  adding: content/IMDB_train/imdb_223.txt (deflated 36%)\n",
            "  adding: content/IMDB_train/imdb_237.txt (deflated 45%)\n",
            "  adding: content/IMDB_train/imdb_116.txt (deflated 46%)\n",
            "  adding: content/IMDB_train/imdb_162.txt (deflated 36%)\n",
            "  adding: content/IMDB_train/imdb_133.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_73.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_209.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_92.txt (deflated 48%)\n",
            "  adding: content/IMDB_train/imdb_210.txt (deflated 44%)\n",
            "  adding: content/IMDB_train/imdb_179.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_99.txt (deflated 47%)\n",
            "  adding: content/IMDB_train/imdb_122.txt (deflated 54%)\n",
            "  adding: content/IMDB_train/imdb_0.txt (deflated 43%)\n",
            "  adding: content/IMDB_train/imdb_77.txt (deflated 42%)\n",
            "  adding: content/IMDB_train/imdb_104.txt (deflated 49%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_r7gEDTZMjf",
        "outputId": "fa015a6d-a136-468d-9849-0f2d135b1125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTIU81ZwRTfw",
        "outputId": "e03b4b1d-b9e8-40e0-d492-6723bfed49dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()"
      ],
      "metadata": {
        "id": "B0pL79tMavFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cmgtiiT7bY-0",
        "outputId": "5a7d5d15-eba0-4559-bed7-e9eda9b47347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv '/content/IMDB_train' '/content/drive/MyDrive/Colab Notebooks/SuperAI_Hackathon/Hackathon_week2_NLP/Resources/BEST_I_CORPUS/TrainingSet'"
      ],
      "metadata": {
        "id": "nJseoSDkkap4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/SuperAI_Hackathon/Hackathon_week2_NLP/Resources/BEST_I_CORPUS/TrainingSet'\n",
        "path = path + \"/IMDB_train\""
      ],
      "metadata": {
        "id": "pRtn9WSumf0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.listdir(path)"
      ],
      "metadata": {
        "id": "iuIL9X7vmaHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJBj3s5Tmnbx",
        "outputId": "413bf3af-cc1e-4a50-e6b2-0bb389eabedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing for Wisesight dataset"
      ],
      "metadata": {
        "id": "aslfkmnqzCn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/word-tokenization/wisesight-1000-samples-tokenised.label'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfC-OJlukmmt",
        "outputId": "2e69b895-dbdf-4ed3-ef49-5e01358febc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-17 16:55:30--  https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/word-tokenization/wisesight-1000-samples-tokenised.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222691 (217K) [text/plain]\n",
            "Saving to: ‘wisesight-1000-samples-tokenised.label’\n",
            "\n",
            "wisesight-1000-samp 100%[===================>] 217.47K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-02-17 16:55:31 (12.2 MB/s) - ‘wisesight-1000-samples-tokenised.label’ saved [222691/222691]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 /content/wisesight-1000-samples-tokenised.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-0dO4k6nDga",
        "outputId": "9f7d05b5-eeed-4fc0-8107-f7d6f82f97c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eucerin| |pro| |acne| |ค่ะ| |ใช้|แล้ว|สิว|ขึ้น|เพิ่ม|ทุกวัน| |มา|ดู|กัน|นะ|คะ| |ว่า|จัด|การ|ปัญหา|สิว|ใน|7|วัน|ได้|รึ|มั่ยยยยยยยย| |ล่า|สุด|ไป|ล้าง|หน้…\n",
            "แพง|เว่อร์| |เบียร์|ช้าง|ต้นทุน|ขวด|ละ|ไม่|ถึง| |50| |ขาย| |120| |😰|😰|😰์\n",
            "ไม่|อยาก|ก้|ไม่|ต้อง|กิน|เพราะ|ตัง|ของ|คุน|แต่|จะ|มา|พูด|ให้|คน|ที่|เขา|ยัง|กิน|อยุ่|รุ้|สึก|แย่|กัน|เพื่อ|?|?|ต่าง|คน|ต่าง|มี|ดุล|พินิจ|ไม่|เหมือน|กัน|ปะ\n",
            "กู|เริ่ม|รำคาญ|โฆษณา|เบียร์|ช้าง|ที่|พี่|เวียร์|เช่น|ละ\n",
            "ตาย|ๆ|HONDA|ทำ|ไร|ไม่|สน|ใจ|โลก|เลย|เขา|มา|4|วาว|แล้ว|ซี|ๆ|ก็|เยอะ|ไม่|เปลี่ยน|โฉม|สัก|ที|เลย\n",
            "สำหรับ|อติล่า|เป็น|การ|ขาย|โตโยต้า|ให้|เหมือน|ขาย|เบนซ์|ค่ะ| |ดู|แพง|ดู|เฉียบ|!| |กรี้ด|สุดดด| #|The|Face|All|Stars|\n",
            "เมื่อวาน|ไป|หา|หมอ|ด้วย|ความ|อยาก|ดื่ม|กาแฟ|เย็น|แต่|เป็น|หวัด|เลย|เดิน|ไป|สั่ง|ลาเต้|ร้อน|ระหว่าง|ที่|รอ|จ่าย|เงิน|ค่า|ยา| |พร้อม|กับ|หยิบ|โดนัท|และ|พิซซ่า|เลย|ถาม|พนักงาน|ว่า|อัน|นี้|ทำ|ใหม่|วัน|นี้|หรือ|เปล่า|ครับ| |ถาม|อยู่|สอง|ครั้ง|แต่|พนักงาน|คน|นั้น|ไม่|ได้|ยิน|อาจ|เป็น|เพราะ|ว่า|เรา|เจ็บ|คอ|เสียง|แหบ|ๆ| |แต่|เธอ|เดิน|หนี|แล้ว|บอก|พนักงาน|อีก|คน|ว่า| |มา|คุย|แทน|พี่|หน่อย|พี่|ไม่|ได้|ยิน|แล้ว|ก็|เดิน|หัน|หลัง|ไป|แบบ|ไม่|ใส่|ใจ|ทั้ง|ๆ|ที่|ตัวเอง|เป็น|พนักงาน|ประจำ|อยู่|แล้ว|ใส่|ฟอร์ม|พนักงาน|อยู่|แต่|ให้|น้อง|ผู้หญิง|น่า|จะ|เป็น|น้อง|ฝึก|งาน|ให้|มา|พูด|กับ|เรา|แทน| |ผม|รู้|สึก|เหมือน|ผม|ไป|สร้าง|ความ|รำคาญ|ยังไง|ไม่|รู้| |สังเกตุ|หลาย|ครั้ง|แล้ว|นะ| |สาขา|นี้|บริการ|แบบ|ไม่|ค่อย|เต็มใจ| |เวลา|ลูกค้า|ถาม|อะไร|หน่อย| |เหมือน|จะ|รำคาญ| |ไม่|เหมือน|ที่|รพ.|พญาไท| |1| |แทบ|จะ|กราบ|ลูกค้า|เลย| |อยาก|ได้|อะไร|จัด|ให้| |บริการ|เลิศ| |หรือ|ว่า|สถานที่|มัน|ไม่|ไฮโซ|หรือ|ไง| |ทำ|ไง|ก็|ขาย|ๆ|ไป| |กาแฟ|แก้ว|ละ|ร้อย|กว่า|ข้าง|นอก|มี|อีก|ตั้ง|หลาย|ร้าน|ถูก|กว่า|เกิน|ครึ่ง| |ซื้อ|กาแฟ|ซื้อ|เบเกอรี่|รวม|กัน|แต่|ละ|ครั้ง|สาม|สี่|ร้อย| |แต่|ก็|รู้สึก|รำคาญ|พนักงาน|ที่|นี่|จริง|ๆ| |ถาม|อะไร|ต้อง|รู้สึก|เกรงใจ|พนักงาน|ทุก|ที|กลัว|เขา|จะ|รำคาญ|เรา| |เลิก|ซื้อ|เด็ดขาด|แล้ว|ครับ| |ขอบคุณ|ที่|ไม่|เต็มใจ|บริการ| |ผม|ก็|ไม่|เต็มใจ|ซื้อ|เหมือน|กัน\n",
            "เคี้ยว|ไม่|ไหว\n",
            "เบียร์|ยู|ไม่|อร่อย|สัด|ๆ|ๆ|ๆ|ๆ|ๆ|ฟ|ๆ\n",
            "พะเยา|ไม่|ร่วม|รายการ|ง่ะ|เธออ|😭\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = []\n",
        "with open(\"/content/wisesight-1000-samples-tokenised.txt\") as fp:\n",
        "    Lines = fp.readlines()\n",
        "    for line in Lines:\n",
        "      sentence.append(line)"
      ],
      "metadata": {
        "id": "lVAbgI6gp8Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNHkTJnkrht1",
        "outputId": "cbf4f4f9-7fc8-438d-8cc5-0deeda0abf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "993"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(sentence, columns =['sentence'])"
      ],
      "metadata": {
        "id": "YsC4k79YsWnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UXIvN3IItpNu",
        "outputId": "2167e7a6-0a2a-46e5-c42b-3ad5fe7a547c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13cde1e3-f1a9-4c10-935f-7be9548f8f85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eucerin| |pro| |acne| |ค่ะ| |ใช้|แล้ว|สิว|ขึ้น...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>แพง|เว่อร์| |เบียร์|ช้าง|ต้นทุน|ขวด|ละ|ไม่|ถึง...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ไม่|อยาก|ก้|ไม่|ต้อง|กิน|เพราะ|ตัง|ของ|คุน|แต่...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>กู|เริ่ม|รำคาญ|โฆษณา|เบียร์|ช้าง|ที่|พี่|เวียร...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ตาย|ๆ|HONDA|ทำ|ไร|ไม่|สน|ใจ|โลก|เลย|เขา|มา|4|ว...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13cde1e3-f1a9-4c10-935f-7be9548f8f85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13cde1e3-f1a9-4c10-935f-7be9548f8f85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13cde1e3-f1a9-4c10-935f-7be9548f8f85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence\n",
              "0  Eucerin| |pro| |acne| |ค่ะ| |ใช้|แล้ว|สิว|ขึ้น...\n",
              "1  แพง|เว่อร์| |เบียร์|ช้าง|ต้นทุน|ขวด|ละ|ไม่|ถึง...\n",
              "2  ไม่|อยาก|ก้|ไม่|ต้อง|กิน|เพราะ|ตัง|ของ|คุน|แต่...\n",
              "3  กู|เริ่ม|รำคาญ|โฆษณา|เบียร์|ช้าง|ที่|พี่|เวียร...\n",
              "4  ตาย|ๆ|HONDA|ทำ|ไร|ไม่|สน|ใจ|โลก|เลย|เขา|มา|4|ว..."
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/syllables_th.txt'"
      ],
      "metadata": {
        "id": "82OLwSmutqgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e77abe-e672-40c2-c939-8dce3d763d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-17 18:15:52--  https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/syllables_th.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126656 (124K) [text/plain]\n",
            "Saving to: ‘syllables_th.txt’\n",
            "\n",
            "\rsyllables_th.txt      0%[                    ]       0  --.-KB/s               \rsyllables_th.txt    100%[===================>] 123.69K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-02-17 18:15:52 (8.93 MB/s) - ‘syllables_th.txt’ saved [126656/126656]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/syllables_th.txt') as fp:\n",
        "    contents = fp.read()\n",
        "    contents = contents.replace('\\n','|')\n",
        "    \n",
        "\n",
        "    with open('/content/syllables.txt', 'w') as f:\n",
        "      f.write(contents)"
      ],
      "metadata": {
        "id": "dsqgXjcE1MB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}